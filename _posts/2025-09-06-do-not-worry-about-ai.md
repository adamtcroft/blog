I’ve been reluctant to voice this publicly for a while, but here’s to having the 
courage to share an opinion…

> Remember, opinions are like ---holes...

I don’t think AI is anything to worry about.

If all you wanted was rage-bait, I gave you that right at the top. If you’re 
interested in reading nuance, feel free to keep reading.

# Why do I think AI is nothing to worry about?
The first reason I'm not worried is: **this has happened before**.

Not so long ago, computers weren't a thing that fit in the palm of your hand. 2" 
tape and cassettes were easier to record on than computers. If you were going to 
have any kind of entertainment career, in the US you had to live in New York, 
Los Angeles, and _maybe_ Nashville (when I was growing up, Nashville meant 
country and blues music).

Technology democratized audio careers - first by the "Pro Tools Rig" and now by 
audio interfaces that plug into iPhones. Technically, people make plenty of 
stuff without even using an interface now.

When access increased, available jobs also increased.  In the 80s and 90s, there 
were a microscopic number of dedicated game composers and/or sound designers. 
All of the people working in film lived in Los Angeles or New York. Today, we 
not only have a comparative explosion of people working explicitly in audio for 
games - but we have professionals niching into specific game types, genres, and 
feelings. This isn't something that would be possible without the proliferation 
of technology.

Along with increased access has also come increased compensation. More people 
make a living doing audio and (and game audio) work now than they did 30-40 
years ago. The demand for entertainment content continued to increase and shows 
no signs of slowing. With ease-of-access came an exponentially larger pool of 
people trying to be working professionals who _don't_ make a living wage, too, 
but those who _do_ are also a significantly larger number than 30-40 years ago.  
The numbers increased all-up.

From my perspective, AI is another loop of this same story of technology 
democratization. Whether we like it or not, the ability to create sound is again 
going to be easier than it was in the past. If you're in your 20's, this means 
you're about to start entering the point of life where you begin to formulate 
your version of the "boomer" complaint "Nobody plays real instruments anymore! They 
all just hit play in Ableton and dance!" I expect to hear something like "Nobody 
makes cool sounds and music in a DAW anymore, they just type a stupid prompt!"

# But won't AI come for all our jobs???
I don't know how yet, and we can speculate all day, but yes, jobs in the future 
will be different. This is a supporting argument for my opinion - as we don't 
have tape machine operators anymore either. So what happened, did they all lose 
their jobs? I'm sure some of them quit the audio industry, if they were old 
enough to retire and didn't want to learn a computer - but the majority of 
working professionals learned how to use computers for recording. They used a 
bunch of software with different names than the DAWs of today - some of which 
still exist and are being upgraded under different brand names. Eventually, most 
people learned to use a "Pro Tools Rig", PC/Mac + external processing hardware 
combo, until those units turned into the laptops and interfaces we have today.

What I expect to happen in the future is a new technology adoption - and it's 
starting with AI chat prompts. From my perspective, that means two things are 
going to happen at the same time:

1. The job of people making sounds and music today will look different in 10 
   years.
2. Increased access will (again) bring increased specialization and those who 
   specialize into _profitable realms_ will be fine.

Anyone who is willing to play and experiment with this new technology (and 
younger folks are historically on the bleeding edge of creative 
experimentation), are going to help define the future of what work looks like. 
But, the same as today, just because you want to make money doing the thing you 
like, it _doesn't mean_ that will be a profitable venture.

In other words - I can't tell you that if you like making sound and music for 
cozy indie games, that said genre is going to be raking in money for lots of 
people to sustain jobs in 10 years. Honestly, I don't know what will be paying 
then, but I'm **highly confident** in your ability to figure it out (and, also, 
our collective ability to complain that it's not exactly what we want and it was 
all better "back in the day").

# What do I think we SHOULD worry about in regard to AI?
If you're worried about AI taking your job, I think you should genuinely worry 
about two areas:

1. Decreased quality (aka "Enshittification")
2. Sticking your head in the sand and yelling on the internet about how AI is 
   evil and we're all doomed

What we're seeing with AI chatbots today is, in my opinion, a bubble somewhat 
equivalent to the "dot com boom" of the 90's. Back then, money was thrown at 
people making webpages, stock prices surged based on the promise of a new thing 
called "e-commerce" which hadn't taken off in earnest. E-commerce proved to be 
real (we just call it "shopping" now), just as I think "AI" (really, LLM tools) 
will stick around, too. However, the reason AI will stick around this time is 
the backing of tech mega corps - Google, Microsoft, Facebook, etc. The 
individual products themselves don't have to be profitable, they just have to 
raise valuations. Their hyped promise does so, so it'll never go away.

But, a thing we're all already seeing (remember, this is _early_ days) and agree 
on is that creative work made by chatbots is extremely derivative of existing 
works and not "good" on its own. This is already resulting in, and will continue 
to result in three things:

1. The speed at which internet content is created and posted is going to be even 
more insane
2. Said works are going to become increasingly low-effort terrible
3. The general public and kids won’t care - this stuff will become super popular

Hence my first point - expect to see quality decreases across the board that the 
general public is fine with. Call it what you want - "low effort content", 
"enshittification", etc - but the reality is that we already see this today, 
too. A lot of short-form video is low-effort, a lot of content is rage-bait 
(which is advertising-driven).

Why should we worry about this? Not because it needs to stop, but because you 
would be wise to evaluate what you're ingesting and spending your time with. 
"Vote with your wallet" is a great adage, and today it's even more important to 
"Vote with your time" or "Vote with your eyes" - ingesting "brain rot" tells the 
world to deliver you more of it.

Don't worry, this isn't the apocalypse - plenty of great entertainment is still 
made today when there's also plenty of low-effort work, too.  I expect this to 
also continue in the future. The great, very cool thing about this is that said 
amazing part of the future is going to be driven by those who creatively use AI 
in ways that we start to accept. I believe we will be (and are already starting 
to be in) a future where generated content becomes a tool in our toolbox - to 
remix and modify, to iterate, and to inspire. There was a day where making music 
by pushing buttons on a laptop was considered "cheating" - now it's absolutely 
normal. This is going to happen again.

The bigger concern I think you should have is seeing all of this, becoming 
overwhelmed, and ignoring it. I'll tell you why...

# What should we do about any of this?
A number of people in the industry that I know and highly respect are barely 
touching AI, out of principle. They don't want to partake in a technology that 
they view comes with dire moral and ethical consequences. I'm not here to 
disagree - please, by all means, choose your own path.

My perspective is that a tool is not moral. If AI is evil, computers were evil 
before it - they have taken jobs and been used for deeply heinous and inhumane 
acts. Also, if I've learned anything from the continued existence of social media - 
technology you dislike will often exist whether you want it to or not.

But, to repeat myself again, I'm not trying to make a convincing case - please 
freely disagree with me. I will posit, however, that if you make no effort to 
give yourself any exposure to the enemy whatsoever - you won't know what you're 
dealing with.

I say this to folks constantly - AI chatbots are a great party trick, but they 
often completely suck in practical creative application.

It is **easy** to find content online made with a chat bot that looks mind 
blowing - realistic video, images, sounds, text, etc. But every time I try and 
recreate this for serious works, my exposure cycle to whatever new AI is getting 
released looks like this:

1. I’m stunned at the marketing examples
2. I may be equally impressed by something a human made
3. I log in and type prompts
4. I’m impressed with the first iteration getting 80% of the way there
5. Further refinements turn out worse, I bash my head against the wall trying to 
jump the gap to get what I want
6. I try again, and repeat 3-5
7. I see that the hyper-specificity required to prompt engineer well is just as 
much work as actually creating code or text or whatever.
8. I use the AI to potentially give me a starting point, but don’t rely on it to 
   make the complete work

If you've never exposed yourself to using AI, then you'd never see this, and it 
would make sense that you'd assume the worst (that the apocalypse is upon us). 
I'm sure there are people _somewhere_ making _something_ incredible and 
functional with AI alone, but that doesn't seem to be the majority use-case.

The real crazy thing we're seeing now is this parlor trick resulting in 
decreased quality ("enshittification") in _commercially released software_, as 
people who aren't software developers are enlisting AI to wholly develop 
software on their behalf (aka "vibe coding"). Like my cycle above, the start of 
this is really impressive looking and can result in a functioning app. However, 
these apps often include security vulnerabilities and/or at least come with poor 
performance. The software development world is already joking that plenty of 
developer jobs in the future are going to be taking poorly coded AI apps and 
fixing them (spoiler: this isn't a joke - I've already seen threads stating "why 
didn't I just hire a developer in the first place?").

Entertainment is going to run into a similar problem. You can fire all your 
artists and audio folks and generate all the content, until the content is bad 
or just won't really generate exactly what you want. I don't think we'll get 
anywhere close to a single person being able to prompt AI to develop a 
spectacular, deeply immersive, and complex game with _zero exposure_ and 
experience to a wide variety of skill areas. Will team size shrink because 
artists and audio professionals can use AI as leverage for speed and iterating? 
Absolutely. I also bet that more, smaller teams will be bankrolled by mega corp 
publishers. I've been talking for at least 5 years already about my expectation 
that the "future of AAA games" is a model equivalent to record labels of the 
1990's - big companies bankrolling lots of bands (small development teams) 
hoping they make hits and derivatives of what's popular.

So if you don't expose yourself to this world a little bit - the world will move 
on regardless. There will be people who eek out work without using any AI tools, 
and they'll use that as a unique selling proposition - but that will be the 
minority.

If I could suggest you do anything, just go play. Try and break the tools of 
today any way you can. I've discovered that I think any time you employ AI to do 
work (especially creative work) on your behalf - it sucks. It doesn't "suck 
because it's AI", it just sucks because it's bad, mindless, and uninspired. It 
creates nothing new, mostly poor mashups if it's left to its own devices. But 
I'm sure you or someone else can take its output and manipulate it into 
something masterful.

What I use it for is largely learning, and thought processing (I'm a 
verbal/written thinker, and this comes in handy when I don't have a human to 
bounce off of). Most everywhere else, I always get into the above frustration 
loop, and I know enough about what I'm doing that I'd often rather make 
something by hand than trudge through a lot of AI yet.

# But Adam, what if you're wrong?!
I could be. I could be deeply misguided on my take here. I don't think I am - 
I've read and lived through enough that I think I see the basic cycle clearly. 
I've also used AI enough to know where I think it's useful and where it isn't. 
But, I could indeed be wrong.

If I am, here's the catch - I still think you'll be fine, because I believe in 
your ability to land on your own two feet. If you've read this far - dear lord - 
you have an aptitude for somewhat nuanced takes at least and can likely navigate 
your way through craziness. I believe in you.

# So what should you remember from this?
1. I don't think AI is the end of the world
2. Jobs are probably going to change in the future, people will flex with it as 
   they have in the past
3. I think you'd be wise to play with AI chat bots a bit
4. You've got this, you're gonna be okay

And with that, you have my "hot take". Hope you enjoyed reading it. If I made 
you mad or you disagree or whatever - bummer but glad these are just opinions. 
If you want to chat further (positively), feel free to comment wherever you 
found this.
